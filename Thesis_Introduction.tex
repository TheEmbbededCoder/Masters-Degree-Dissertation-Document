%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                      %
%     File: Thesis_Introduction.tex                                    %
%     Tex Master: Thesis.tex                                           %
%                                                                      %
%     Author: Francisco Mendes                                           %
%     Last modified :  31 Jul 2020                                      %
%                                                                      %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Introduction}
\label{chapter:introduction}

Graphical Processing Units (\acrshort{gpu}s) were brought to life in the advent of computer graphics in the hopes of improving the capabilities of 3D games. However, the increased parallel computing capabilities exhibited by these devices made them highly appealing to running more general computational demanding applications, coining the term \acrshort{gpgpu} - General-Purpose Graphical Processing Units.

Along this path, the development of new architectural generations of \acrshort{gpu} devices has traditionally aimed at improving performance and throughput. However, having already reached the maximum supported power consumption and with device fabrication techniques being harder and harder to minimize, extra performance gains need to come while keeping the pace for a greater \acrshort{gpu}s energy-efficiency.

Researchers have been looking for into ways of decreasing the power consumption to improve energy efficiency with some degree of success, with new architectural designs targetting, for example, operation with lower precision encoding (reduced number of bits) to reduce the number of combinatorial logic. Nevertheless, techniques such as Dynamic Voltage and Frequency Scaling (\acrshort{dvfs}) are still the ones that are having a more direct impact on the industry, by being widely available on current out-of-the-shelf devices. These systems' working principle is to carefully select the used voltage-frequency (V-F) levels, in order to target the current \acrshort{gpu} state. Since the dissipated power is directly proportional to the applied frequency and to the square of the applied voltage, the variation of these parameters directly and significantly impacts the devices' power and energy consumption.

In theory, \acrshort{dvfs} systems should be able to select the fittest V-F configuration. Nevertheless, practical implementations of such mechanisms seem to exhibit two flaws: i) they do not consider the running application characteristics and ii) use pre-defined V-F pairs that are conservatively selected by manufacturers. In particular, at each frequency level, the chosen voltage supply is set at a level that leaves a significant voltage margin in relation to the necessary one. Such margin is put in place to guarantee a safe operation under all conditions. However, recent studies prompt the idea that such conservative voltage margin is leaving a significant energy-efficiency gain on the table~\cite{leng_safe_2015}. 

Supported on this observation, it has been recognized that the correct utilization of non-conventional V-F pairs may improve the energy-efficiency of already deployed \acrshort{gpu}s.

One particular application domain that can significantly benefit from such energy-efficiency improvements is Deep Learning, and more specifically, Deep Neural Networks (\acrshort{dnn}s). These algorithms are having a significant impact on industry and society by allowing for important breakthroughs in many application domains, such as computer vision, speech recognition, natural language processing, drug discovery, genomics, etc \cite{shrestha_review_2019}. However, \acrshort{dnn}s are usually characterized by significant computational burdens, particularly when considering the training of very deep and complex networks, dealing with high dimensional data, such as images and videos. Another important characteristic of \acrshort{dnn}s is their tolerance to a certain degree of computation errors \cite{zhang_approxann_2015}, without any significant change in the training and inference results. 

Therefore, creating a novel \acrshort{dvfs} system that explores and selects non-conventional V-F pairs by considering the specific target application characteristics can allow for a substantial decrease in the energy consumed to train and deploy Deep Learning applications~\cite{tang_impact_2019}.




% In the last few years, Deep Neural Networks (\acrshort{dnn}s) have had a significant impact in industry and society by allowing for important breakthroughs in many application domains, such as computer vision, speech recognition, natural language processing, drug discovery, genomics, etc \cite{shrestha_review_2019}.

% However, \acrshort{dnn}s are usually characterized by significant computational burdens, particularly when considering the training of very deep and complex networks, dealing with high dimensional data, such as images and videos. For such purpose, researchers (and data scientists, in general) often rely on accelerators, such as Graphical Processing Units (\acrshort{gpu}s), to cope with the associated computational burden and reduce the training time. \acrshort{gpu}s differ from conventional processors by including thousands of computing cores (Compute Units - \acrshort{cu}s) and a large bandwidth memory module. As a result, they are able to execute the same instruction over massive amounts of data. Due to their versatility and compute power, \acrshort{gpu}s are now commonly deployed on most supercomputers, data centers, and other computational infrastructures related to artificial intelligence algorithms' development.



% Additionally, several software frameworks, algorithms and techniques have been proposed to manage and optimize the execution of \acrshort{dnn} on \acrshort{gpu} (e.g., the work of Mittal~\cite{mittal_survey_2019}). However, most optimization techniques neglect the training phase's energy impact, usually resulting in considerable costs. 

% To overcome this problem, researchers have also explored other solutions that allow mitigating the energy impact of neural network training. One particular and common approach relies on the use of low-precision arithmetic (e.g., demonstrated by Nabavinejad~ \cite{nabavinejad_coordinated_2019}), eventually trading network accuracy with increased processing performance and lower energy consumption.

% Researchers have also looked at alternative approaches, such as exploiting Dynamic Voltage and Frequency Scaling (\acrshort{dvfs}) on both the inference and training phases. In fact, by carefully selecting the used voltage-frequency (V-F) levels, significant energy savings can be obtained, although depending on the considered \acrshort{dnn} architecture and computing  device~\cite{tang_impact_2019}. This is achieved through a careful balance between the different GPU components' performance and power consumption (particularly the core and global memory) to minimize stalls in the compute cores. In fact, not only can \acrshort{dvfs} be used to decrease the power consumption, but it can also boost the system performance~\cite{tang_impact_2019}, by increasing the voltage and frequency levels (as long as the GPU total power envelope and thermal limits are not surpassed).

% Nevertheless, most state-of-the-art works only consider tightly coupled V-F levels, often predefined by \acrshort{gpu} manufacturers and neglecting the voltage margin that is usually introduced to guarantee fail-safe designs, as well as its variation with the kernel instruction sequence and the corresponding use of specific \acrshort{gpu} components. Supported on this observation, this work tries to increase the energy-efficiency of \acrshort{gpu}s by understanding and characterizing their behavior when subject to non-conventional V-F scaling. 
% It also tries to go one step further by creating an optimization mechanism that automatically selects the V-F pair that better suits the running application as well as the specific characteristics of the computing device.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Objectives}
\label{section:objectives}

To uncover the use of non-conventional V-F scaling, this thesis focuses on the following objectives:

\begin{itemize}
\item Access the viability of using non-conventional V-F pairs on regular \acrshort{gpu}s.
\item Characterize the behavior of \acrshort{gpu} architectures to non-conventional V-F pairs.
\item Develop a dynamic non-conventional V-F controlling and optimization mechanism that improves the \textit{performance}, \textit{energy consumption} or \textit{energy-efficiency} of \acrshort{gpu}s.
\item Safely apply non-conventional V-F scaling on Deep Learning applications, characterizing the behavior of the training procedure.
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Main Contributions}
\label{section:main_contri}

The work conducted in the scope of this dissertation contributes to open the discussion of further improving the current \acrshort{gpu} \acrshort{dvfs} systems, by exploring the conservative voltage guardband put in place by device manufacturers. The developed work demonstrates that non-conventional voltage-frequency (V-F) pairs are mostly allowed by out-of-the-shelf devices, leading to great energy-efficiency benefits and, in some cases, even performance enhancements. 

To demonstrate and validate the use of those new V-F configurations, a new methodology was developed to test each architectural component of the \acrshort{gpu}, analyzing and evaluating its specific voltage margin and characterizing their energy-performance behavior when subject to such configurations. The methodology was tested in two different architectural generation devices, both of them exhibiting a high tolerance to undervoltage.

Furthermore, to more easily benefit from the usable execution space that was defined by executing the set of benchmarks that compose the formulated methodology, a new V-F optimization mechanism was devised. The mechanism makes use of the native code repetition patterns, usually observed in \acrshort{gpgpu} applications, to improve the applied V-F pair iteratively, taking into account not only the \acrshort{gpu} power consumption, utilization and temperature (as it is done by current \acrshort{dvfs} systems) but also the running application characteristics. With the use of such a conceived optimization mechanism, it is possible to perform dynamic voltage and frequency scaling while taking into account each application's intrinsic behavior and benefiting from the energy-efficiency improvements granted by the non-conventional V-F pairs.

To evaluate the proposed methodology and optimization mechanism, it was applied to the training procedure of deep learning applications, specifically the training of convolutional neural networks. The conducted evaluation explored the voltage margins and behavior of the fundamental algorithms that compose this type of operations, the distribution of the computational error that appears when using the lowest allowed voltage by the architecture and finally, the energy-efficiency improvement that is achieved by the V-F optimization mechanism when targetting the execution of this type of algorithms. In particular, the description of the performed work targetting the training of neural networks helps to understand the complete flow of actions that should be taken to take full advantage of exploring the conservative voltage guardband put in place by device manufacturers, and with that, improve the energy-efficiency of current out-of-the-shelf \acrshort{gpu}s.

The main scientiﬁc contributions of this work have been published for communication in the following conference:

\begin{itemize}
    \item F. Mendes, P. Tómas and N. Roma, "Exploiting non-conventional DVFS on GPUs: application to Deep Learning", IEEE 32nd International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD'2020), 2020.
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Dissertation Outline}
\label{section:outline}

This dissertation is organized in 5 chapters and one appendix, with the following outline:
\begin{itemize}
    \item \textbf{Chapter 2 - Background:} This chapter presents a summary of the current state-of-the-art related to the subject in focus on this dissertation. First, it introduces an overview of general-purpose computing on \acrshort{gpu}s, providing a summary of their architecture and programming model. It presents the key concepts that should be present when developing for this kind of devices and the standard programming interfaces between the \acrshort{gpu} and the host  \acrshort{cpu}. A bottom-up approach is also drawn to present the fundamental concepts of frequency and voltage scaling on \acrshort{cmos} devices, and how they translate to the current \acrshort{dvfs} systems presented in out-of-the-shelf \acrshort{gpu}s. It finalizes by granting a sketch of how better exploring and going against the conventional voltage-frequency scaling allows for better energy efficiency of \acrshort{gpu}s, being that the stepping stone of this dissertation. 
    \item \textbf{Chapter 3 - GPU architectural characterization to decoupled V-F:} In this chapter, the developed methodology to characterize the use of non-conventional V-F scaling is presented. The chapter starts by exploring each developed stressing component benchmark's motivation and objectives, and it follows by testing the methodology in two different \acrshort{gpu} architectures. The methodology is used to: determine the minimum voltage allowed by each architectural component and evaluate the performance, energy consumption and energy efficiency, when prompting non-conventional V-F pairs on them. It finishes by experimentally testing the effects of temperature on the undervoltage capabilities of the \acrshort{gpu} architecture.
    \item \textbf{Chapter 4 - V-F Optimization Mechanism:} This chapter analyses and proposes a solution to dynamically adjust the frequency and voltage using the newly tested non-conventional V-F pairs. Programmers can execute their algorithms using this tool, while the most energy-efficient V-F configuration is being discovered, targetting the current \acrshort{gpu} state and performance metrics, and application output.
    \item \textbf{Chapter 5 - Application to Deep Learning:} In this chapter, the previous two chapters' results are combined and used to apply the developed methodology on a deep learning application. This chapter has three objectives: showcase the practical advantages of extending the default voltage-frequency scaling with non-conventional V-F pairs on a target application; evaluate the use of the developed optimization mechanism, and, overall, the chapter indicates how a user should proceed to safely and beneficially use the work developed in this dissertation.
    \item \textbf{Chapter 6 - Conclusions:} This final chapter presents the accomplished results from this work and the possible research directions to take in future work.
    \item \textbf{Appendix A:} This appendix presents all the necessary steps and commands to control the rocm-smi tool with the objective of setting the desired voltage-frequency pair on the target \acrshort{gpu}s.
\end{itemize}

